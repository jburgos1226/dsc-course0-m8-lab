{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7485d62",
   "metadata": {},
   "source": [
    "# Aviation Accidents Analysis\n",
    "\n",
    "You are part of a consulting firm that is tasked to do an analysis of commercial and passenger jet airline safety. The client (an airline/airplane insurer) is interested in knowing what types of aircraft (makes/models) exhibit low rates of total destruction and low likelihood of fatal or serious passenger injuries in the event of an accident. They are also interested in any general variables/conditions that might be at play. Your analysis will be based off of aviation accident data accumulated from the years 1948-2023. \n",
    "\n",
    "Our client is only interested in airplane makes/models that are professional builds and could potentially still be active. Assume a max lifetime of 40 years for a make/model retirement and make sure to filter your data accordingly (i.e. from 1983 onwards). They would also like separate recommendations for small aircraft vs. larger passenger models. **In addition, make sure that claims that you make are statistically robust and that you have enough samples when making comparisons between groups.**\n",
    "\n",
    "\n",
    "In this summative assessment you will demonstrate your ability to:\n",
    "- **Use Pandas to load, inspect, and clean the dataset appropriately.**\n",
    "- **Transform relevant columns to create measures that address the problem at hand.**\n",
    "- conduct EDA: visualization and statistical measures to systematically understand the structure of the data\n",
    "- recommend a set of airplanes and makes conforming to the client's request and identify at least *two* factors contributing to airplane safety. You must provide supporting evidence (visuals, summary statistics, tables) for each claim you make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e582c5",
   "metadata": {},
   "source": [
    "### Make relevant library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a72188a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fc321",
   "metadata": {},
   "source": [
    "## Data Loading and Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57becc28",
   "metadata": {},
   "source": [
    "### Load in data from the relevant directory and inspect the dataframe.\n",
    "- inspect NaNs, datatypes, and summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85235fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Event.Id Investigation.Type Accident.Number  Event.Date  \\\n",
      "0  20001218X45444           Accident      SEA87LA080  1948-10-24   \n",
      "1  20001218X45447           Accident      LAX94LA336  1962-07-19   \n",
      "2  20061025X01555           Accident      NYC07LA005  1974-08-30   \n",
      "3  20001218X45448           Accident      LAX96LA321  1977-06-19   \n",
      "4  20041105X01764           Accident      CHI79FA064  1979-08-02   \n",
      "\n",
      "          Location        Country   Latitude   Longitude Airport.Code  \\\n",
      "0  MOOSE CREEK, ID  United States        NaN         NaN          NaN   \n",
      "1   BRIDGEPORT, CA  United States        NaN         NaN          NaN   \n",
      "2    Saltville, VA  United States  36.922223  -81.878056          NaN   \n",
      "3       EUREKA, CA  United States        NaN         NaN          NaN   \n",
      "4       Canton, OH  United States        NaN         NaN          NaN   \n",
      "\n",
      "  Airport.Name  ... Purpose.of.flight Air.carrier Total.Fatal.Injuries  \\\n",
      "0          NaN  ...          Personal         NaN                  2.0   \n",
      "1          NaN  ...          Personal         NaN                  4.0   \n",
      "2          NaN  ...          Personal         NaN                  3.0   \n",
      "3          NaN  ...          Personal         NaN                  2.0   \n",
      "4          NaN  ...          Personal         NaN                  1.0   \n",
      "\n",
      "  Total.Serious.Injuries Total.Minor.Injuries Total.Uninjured  \\\n",
      "0                    0.0                  0.0             0.0   \n",
      "1                    0.0                  0.0             0.0   \n",
      "2                    NaN                  NaN             NaN   \n",
      "3                    0.0                  0.0             0.0   \n",
      "4                    2.0                  NaN             0.0   \n",
      "\n",
      "  Weather.Condition  Broad.phase.of.flight   Report.Status Publication.Date  \n",
      "0               UNK                 Cruise  Probable Cause              NaN  \n",
      "1               UNK                Unknown  Probable Cause       19-09-1996  \n",
      "2               IMC                 Cruise  Probable Cause       26-02-2007  \n",
      "3               IMC                 Cruise  Probable Cause       12-09-2000  \n",
      "4               VMC               Approach  Probable Cause       16-04-1980  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/karinaburgos/Documents/Flatiron/dsc-course0-m8-lab/data/AviationData.csv', encoding='latin-1', low_memory=False)\n",
    "# Inspect the first few rows of the dataframe\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "31ab2b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88889 entries, 0 to 88888\n",
      "Data columns (total 31 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Event.Id                88889 non-null  object \n",
      " 1   Investigation.Type      88889 non-null  object \n",
      " 2   Accident.Number         88889 non-null  object \n",
      " 3   Event.Date              88889 non-null  object \n",
      " 4   Location                88837 non-null  object \n",
      " 5   Country                 88663 non-null  object \n",
      " 6   Latitude                34382 non-null  object \n",
      " 7   Longitude               34373 non-null  object \n",
      " 8   Airport.Code            50132 non-null  object \n",
      " 9   Airport.Name            52704 non-null  object \n",
      " 10  Injury.Severity         87889 non-null  object \n",
      " 11  Aircraft.damage         85695 non-null  object \n",
      " 12  Aircraft.Category       32287 non-null  object \n",
      " 13  Registration.Number     87507 non-null  object \n",
      " 14  Make                    88826 non-null  object \n",
      " 15  Model                   88797 non-null  object \n",
      " 16  Amateur.Built           88787 non-null  object \n",
      " 17  Number.of.Engines       82805 non-null  float64\n",
      " 18  Engine.Type             81793 non-null  object \n",
      " 19  FAR.Description         32023 non-null  object \n",
      " 20  Schedule                12582 non-null  object \n",
      " 21  Purpose.of.flight       82697 non-null  object \n",
      " 22  Air.carrier             16648 non-null  object \n",
      " 23  Total.Fatal.Injuries    77488 non-null  float64\n",
      " 24  Total.Serious.Injuries  76379 non-null  float64\n",
      " 25  Total.Minor.Injuries    76956 non-null  float64\n",
      " 26  Total.Uninjured         82977 non-null  float64\n",
      " 27  Weather.Condition       84397 non-null  object \n",
      " 28  Broad.phase.of.flight   61724 non-null  object \n",
      " 29  Report.Status           82505 non-null  object \n",
      " 30  Publication.Date        75118 non-null  object \n",
      "dtypes: float64(5), object(26)\n",
      "memory usage: 21.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Inspect NaNs and datatypes\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e102fff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event.Id                      0\n",
      "Investigation.Type            0\n",
      "Accident.Number               0\n",
      "Event.Date                    0\n",
      "Location                     52\n",
      "Country                     226\n",
      "Latitude                  54507\n",
      "Longitude                 54516\n",
      "Airport.Code              38757\n",
      "Airport.Name              36185\n",
      "Injury.Severity            1000\n",
      "Aircraft.damage            3194\n",
      "Aircraft.Category         56602\n",
      "Registration.Number        1382\n",
      "Make                         63\n",
      "Model                        92\n",
      "Amateur.Built               102\n",
      "Number.of.Engines          6084\n",
      "Engine.Type                7096\n",
      "FAR.Description           56866\n",
      "Schedule                  76307\n",
      "Purpose.of.flight          6192\n",
      "Air.carrier               72241\n",
      "Total.Fatal.Injuries      11401\n",
      "Total.Serious.Injuries    12510\n",
      "Total.Minor.Injuries      11933\n",
      "Total.Uninjured            5912\n",
      "Weather.Condition          4492\n",
      "Broad.phase.of.flight     27165\n",
      "Report.Status              6384\n",
      "Publication.Date          13771\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "419e8313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Number.of.Engines  Total.Fatal.Injuries  Total.Serious.Injuries  \\\n",
      "count       82805.000000          77488.000000            76379.000000   \n",
      "mean            1.146585              0.647855                0.279881   \n",
      "std             0.446510              5.485960                1.544084   \n",
      "min             0.000000              0.000000                0.000000   \n",
      "25%             1.000000              0.000000                0.000000   \n",
      "50%             1.000000              0.000000                0.000000   \n",
      "75%             1.000000              0.000000                0.000000   \n",
      "max             8.000000            349.000000              161.000000   \n",
      "\n",
      "       Total.Minor.Injuries  Total.Uninjured  \n",
      "count          76956.000000     82977.000000  \n",
      "mean               0.357061         5.325440  \n",
      "std                2.235625        27.913634  \n",
      "min                0.000000         0.000000  \n",
      "25%                0.000000         0.000000  \n",
      "50%                0.000000         1.000000  \n",
      "75%                0.000000         2.000000  \n",
      "max              380.000000       699.000000  \n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b8cc7",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23efd78",
   "metadata": {},
   "source": [
    "### Filtering aircrafts and events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c399343",
   "metadata": {},
   "source": [
    "We want to filter the dataset to include aircraft that the client is interested in an analysis of:\n",
    "- inspect relevant columns\n",
    "- figure out any reasonable imputations\n",
    "- filter the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a2b7eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aircraft.Category unique values:\n",
      "Aircraft.Category\n",
      "Airplane             27617\n",
      "Helicopter            3440\n",
      "Glider                 508\n",
      "Balloon                231\n",
      "Gyrocraft              173\n",
      "Weight-Shift           161\n",
      "Powered Parachute       91\n",
      "Ultralight              30\n",
      "Unknown                 14\n",
      "WSFT                     9\n",
      "Powered-Lift             5\n",
      "Blimp                    4\n",
      "UNK                      2\n",
      "Rocket                   1\n",
      "ULTR                     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# inspect relevant columns\n",
    "\n",
    "print(\"Aircraft.Category unique values:\")\n",
    "print(df['Aircraft.Category'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f01ef370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amateur.Built unique values:\n",
      "Amateur.Built\n",
      "No     80312\n",
      "Yes     8475\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Amateur.Built unique values:\")\n",
    "print(df['Amateur.Built'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9901acf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event.Date sample:\n",
      "0    1948-10-24\n",
      "1    1962-07-19\n",
      "2    1974-08-30\n",
      "3    1977-06-19\n",
      "4    1979-08-02\n",
      "Name: Event.Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Event.Date sample:\")\n",
    "print(df['Event.Date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c3a839f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values - Aircraft.Category: 56602\n",
      "Missing values - Amateur.Built: 102\n",
      "Missing values - Event.Date: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(f\"Missing values - Aircraft.Category: {df['Aircraft.Category'].isnull().sum()}\")\n",
    "print(f\"Missing values - Amateur.Built: {df['Amateur.Built'].isnull().sum()}\")\n",
    "print(f\"Missing values - Event.Date: {df['Event.Date'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7084cef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (88889, 31)\n"
     ]
    }
   ],
   "source": [
    "#filter the dataset\n",
    "print(f\"Original shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bdc5b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After airplane filter: (27617, 31)\n"
     ]
    }
   ],
   "source": [
    "# Filter for airplanes only\n",
    "df = df[df['Aircraft.Category'] == 'Airplane']\n",
    "print(f\"After airplane filter: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "728640d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After professional builds filter: (24417, 31)\n"
     ]
    }
   ],
   "source": [
    "# Filter for professional builds (Amateur.Built = 'No')\n",
    "df = df[df['Amateur.Built'] == 'No']\n",
    "print(f\"After professional builds filter: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21ed493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape after date filter: (21428, 31)\n"
     ]
    }
   ],
   "source": [
    "# Filter for events within last 40 years\n",
    "df['Event.Date'] = pd.to_datetime(df['Event.Date'], errors='coerce')\n",
    "cutoff_date = pd.Timestamp.now() - pd.DateOffset(years=40)\n",
    "df = df[df['Event.Date'] >= cutoff_date]\n",
    "print(f\"Final shape after date filter: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d26002",
   "metadata": {},
   "source": [
    "### Cleaning and constructing Key Measurables\n",
    "\n",
    "Injuries and robustness to destruction are a key interest point for the client. Clean and impute relevant columns and then create derived fields that best quantifies what the client wishes to track. **Use commenting or markdown to explain any cleaning assumptions as well as any derived columns you create.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b08f8",
   "metadata": {},
   "source": [
    "**Construct metric for fatal/serious injuries**\n",
    "\n",
    "*Hint:* Estimate the total number of passengers on each flight. The likelihood of serious / fatal injury can be estimated as a fraction from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ef28a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injury columns inspection:\n",
      "       Total.Fatal.Injuries  Total.Serious.Injuries  Total.Minor.Injuries  \\\n",
      "11898                   1.0                     1.0                   4.0   \n",
      "12384                   NaN                     NaN                   NaN   \n",
      "12683                   NaN                     NaN                   NaN   \n",
      "13114                  17.0                     NaN                   NaN   \n",
      "14259                   3.0                     2.0                   NaN   \n",
      "\n",
      "       Total.Uninjured  \n",
      "11898              NaN  \n",
      "12384              4.0  \n",
      "12683              4.0  \n",
      "13114              NaN  \n",
      "14259              NaN  \n"
     ]
    }
   ],
   "source": [
    "#injury metrics\n",
    "print(\"Injury columns inspection:\")\n",
    "print(df[['Total.Fatal.Injuries', 'Total.Serious.Injuries', 'Total.Minor.Injuries', 'Total.Uninjured']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "861d609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning: i'm filling any missing injury values with 0 . im assuming that if the value is missing, it means there were no injuries reported.\n",
    "df['Total.Fatal.Injuries'] = df['Total.Fatal.Injuries'].fillna(0)\n",
    "df['Total.Serious.Injuries'] = df['Total.Serious.Injuries'].fillna(0)\n",
    "df['Total.Minor.Injuries'] = df['Total.Minor.Injuries'].fillna(0)\n",
    "df['Total.Uninjured'] = df['Total.Uninjured'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4bea38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derived metric: i'm summing all of the injuries categories to estimate the total number of passengers\n",
    "df['Total.Passengers'] = (df['Total.Fatal.Injuries'] +\n",
    "                          df['Total.Serious.Injuries'] +\n",
    "                          df['Total.Minor.Injuries'] +\n",
    "                            df['Total.Uninjured'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b08cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derived metric: fatal/serious injury rate as requested by client\n",
    "df['Serious_Fatal_Rate'] = (df['Total.Fatal.Injuries'] + df['Total.Serious.Injuries']) / df['Total.Passengers']\n",
    "df['Serious_Fatal_Rate'] = df['Serious_Fatal_Rate'].fillna(0)  # Handle division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aca297b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average serious/fatal injury rate: 0.272\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average serious/fatal injury rate: {df['Serious_Fatal_Rate'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89136b",
   "metadata": {},
   "source": [
    "**Aircraft.Damage**\n",
    "- identify and execute any cleaning tasks\n",
    "- construct a derived column tracking whether an aircraft was destroyed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "91b518b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aircraft damage columns inspection:\n",
      "Aircraft.damage\n",
      "Substantial    16984\n",
      "Destroyed       2310\n",
      "Minor            812\n",
      "Unknown           97\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#aircraft damage metrics\n",
    "print(\"Aircraft damage columns inspection:\")\n",
    "print(df['Aircraft.damage'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4a5bcec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clea - Aircraft damage columns inspection:\n",
      "Aircraft.damage\n",
      "Substantial    16984\n",
      "Destroyed       2310\n",
      "Unknown         1322\n",
      "Minor            812\n",
      "Name: count, dtype: int64\n",
      "Missing values in Aircraft.damage after filling: 0\n"
     ]
    }
   ],
   "source": [
    "# cleaning: Fill missing damage values with 'Unknown'\n",
    "# Rationale: Missing damage assessment likely indicates incomplete reporting\n",
    "# rather than no damage, so preserve records with explicit unknown category\n",
    "df['Aircraft.damage'] = df['Aircraft.damage'].fillna('Unknown')\n",
    "print(\"Clea - Aircraft damage columns inspection:\")\n",
    "print(df['Aircraft.damage'].value_counts())\n",
    "print(f\"Missing values in Aircraft.damage after filling: {df['Aircraft.damage'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6d1c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derived column - Aircraft_Destroyed\n",
    "# Purpose: Binary indicator (1=destroyed, 0=not destroyed) for destruction analysis\n",
    "# Addresses client interest in aircraft robustness to complete loss\n",
    "df['Aircraft_Destroyed'] = (df['Aircraft.damage'] == 'Destroyed').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "970df34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aircraft destruction rate: 0.108\n",
      "Final dataset shape: (21428, 34)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Aircraft destruction rate: {df['Aircraft_Destroyed'].mean():.3f}\")\n",
    "print(f\"Final dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8af9b",
   "metadata": {},
   "source": [
    "### Investigate the *Make* column\n",
    "- Identify cleaning tasks here\n",
    "- List cleaning tasks clearly in markdown\n",
    "- Execute the cleaning tasks\n",
    "- For your analysis, keep Makes with a reasonable number (you can put the threshold at 50 though lower could work as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cf9005cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make column basic info:\n",
      "Total records: 21428\n",
      "Missing values: 3\n",
      "Unique makes: 1332\n",
      "\n",
      "Top 20 most common makes:\n",
      "Make\n",
      "CESSNA                4867\n",
      "PIPER                 2803\n",
      "Cessna                2274\n",
      "Piper                 1183\n",
      "BOEING                1037\n",
      "BEECH                 1018\n",
      "Beech                  411\n",
      "MOONEY                 238\n",
      "Boeing                 225\n",
      "CIRRUS DESIGN CORP     218\n",
      "AIR TRACTOR INC        217\n",
      "AIRBUS                 215\n",
      "BELLANCA               158\n",
      "AERONCA                149\n",
      "MAULE                  144\n",
      "Mooney                 125\n",
      "EMBRAER                123\n",
      "Air Tractor            117\n",
      "LUSCOMBE                95\n",
      "DEHAVILLAND             91\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of Make values (first 20 unique):\n",
      "['Cessna' 'Lake' 'Lockheed' 'Piper' 'Grumman' 'Douglas' 'Mooney'\n",
      " 'Swearingen' 'Boeing' 'Gulfstream' 'Beech' 'Helio' 'Airbus Industrie'\n",
      " 'Univair' 'Maule' 'Taylorcraft' 'Globe' 'Embraer'\n",
      " 'Consolidated Aeronautics Inc.' 'Mcdonnell Douglas']\n"
     ]
    }
   ],
   "source": [
    "# Initial inspection of Make column\n",
    "print(\"Make column basic info:\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Missing values: {df['Make'].isnull().sum()}\")\n",
    "print(f\"Unique makes: {df['Make'].nunique()}\")\n",
    "print(\"\\nTop 20 most common makes:\")\n",
    "print(df['Make'].value_counts().head(20))\n",
    "\n",
    "print(\"\\nSample of Make values (first 20 unique):\")\n",
    "print(df['Make'].dropna().unique()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732cc3fd",
   "metadata": {},
   "source": [
    "Cleaning Tasks Identified:\n",
    "\n",
    "1) Handle Missing Values\n",
    "   - Fill missing Make values with 'Unknown'\n",
    "   - Preserve records for analysis rather than dropping\n",
    "\n",
    "2) Standardize Case and Formatting\n",
    "   - Convert all makes to title case for consistency\n",
    "   - Remove leading/trailing whitespace\n",
    "   - Standardize common abbreviations\n",
    "\n",
    "3) Consolidate Similar Makes\n",
    "   - Merge case variations (e.g., 'BOEING' vs 'Boeing')\n",
    "   - Handle common misspellings or variations\n",
    "   - Standardize manufacturer names\n",
    "\n",
    "4) Filter by Frequency Threshold\n",
    "   - Keep only makes with 50+ occurrences\n",
    "   - Group remaining makes as 'Other' for analysis focus\n",
    "\n",
    "5) Data Validation\n",
    "   - Check for unrealistic or invalid entries\n",
    "   - Verify manufacturer names against known aircraft makers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5357c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning: 3\n",
      "Missing values after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Handle missing values\n",
    "print(f\"Missing values before cleaning: {df['Make'].isnull().sum()}\")\n",
    "df['Make'] = df['Make'].fillna('Unknown')\n",
    "print(f\"Missing values after cleaning: {df['Make'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b006139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Standardize formatting\n",
    "# Remove whitespace and convert to title case\n",
    "df['Make'] = df['Make'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b79f1eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique makes after standardization: 1077\n"
     ]
    }
   ],
   "source": [
    "# Task 3: Consolidate common variations and standardize names\n",
    "make_standardization = {\n",
    "    'Cessna Aircraft Company': 'Cessna',\n",
    "    'Piper Aircraft Corporation': 'Piper', \n",
    "    'Beech Aircraft Corporation': 'Beechcraft',\n",
    "    'Beech': 'Beechcraft',\n",
    "    'Air Tractor Inc': 'Air Tractor',\n",
    "    'Boeing Company': 'Boeing',\n",
    "    'Airbus Industrie': 'Airbus',\n",
    "    'Mcdonnell Douglas': 'McDonnell Douglas',\n",
    "    'Mcdonnell Douglas Corporation': 'McDonnell Douglas',\n",
    "    'Bell Helicopter Company': 'Bell',\n",
    "    'Bell Helicopter Textron': 'Bell',\n",
    "    'Mooney Aircraft Corporation': 'Mooney',\n",
    "    'Cirrus Design Corp': 'Cirrus'\n",
    "}\n",
    "\n",
    "# Apply standardization\n",
    "for old_name, new_name in make_standardization.items():\n",
    "    df.loc[df['Make'] == old_name, 'Make'] = new_name\n",
    "\n",
    "print(f\"Unique makes after standardization: {df['Make'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0b7a716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Makes with 50+ occurrences: 34\n",
      "Top makes meeting threshold:\n",
      "Make\n",
      "Cessna         7152\n",
      "Piper          3997\n",
      "Beechcraft     1447\n",
      "Boeing         1271\n",
      "Air Tractor     425\n",
      "Mooney          364\n",
      "Cirrus          357\n",
      "Airbus          285\n",
      "Bellanca        219\n",
      "Maule           215\n",
      "Aeronca         200\n",
      "Champion        158\n",
      "Embraer         153\n",
      "Grumman         147\n",
      "Luscombe        141\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Filter by frequency threshold (50+ occurrences)\n",
    "make_counts = df['Make'].value_counts()\n",
    "frequent_makes = make_counts[make_counts >= 50].index.tolist()\n",
    "\n",
    "print(f\"\\nMakes with 50+ occurrences: {len(frequent_makes)}\")\n",
    "print(\"Top makes meeting threshold:\")\n",
    "print(make_counts[make_counts >= 50].head(15))\n",
    "\n",
    "# Create filtered dataset and group infrequent makes as 'Other'\n",
    "df['Make_Cleaned'] = df['Make'].apply(lambda x: x if x in frequent_makes else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c99a3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Make_Cleaned statistics:\n",
      "Total unique makes: 35\n",
      "Records with 'Other': 3456\n",
      "Records with 'Unknown': 0\n",
      "\n",
      "Final distribution of cleaned makes:\n",
      "Make_Cleaned\n",
      "Cessna                            7152\n",
      "Piper                             3997\n",
      "Other                             3456\n",
      "Beechcraft                        1447\n",
      "Boeing                            1271\n",
      "Air Tractor                        425\n",
      "Mooney                             364\n",
      "Cirrus                             357\n",
      "Airbus                             285\n",
      "Bellanca                           219\n",
      "Maule                              215\n",
      "Aeronca                            200\n",
      "Champion                           158\n",
      "Embraer                            153\n",
      "Grumman                            147\n",
      "Luscombe                           141\n",
      "Stinson                            129\n",
      "McDonnell Douglas                  109\n",
      "North American                     106\n",
      "Dehavilland                         95\n",
      "Taylorcraft                         93\n",
      "Aero Commander                      90\n",
      "Aviat Aircraft Inc                  76\n",
      "Socata                              75\n",
      "Diamond Aircraft Ind Inc            74\n",
      "De Havilland                        72\n",
      "Aviat                               70\n",
      "Bombardier Inc                      65\n",
      "Raytheon Aircraft Company           62\n",
      "Grumman Acft Eng Cor-Schweizer      58\n",
      "Rockwell International              58\n",
      "Ayres                               55\n",
      "Ercoupe                             52\n",
      "American Champion Aircraft          52\n",
      "Bombardier                          50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cleaning complete. Shape: (21428, 35)\n",
      "Make column ready for analysis with 35 categories\n"
     ]
    }
   ],
   "source": [
    "# Task 5: Final validation\n",
    "print(f\"\\nFinal Make_Cleaned statistics:\")\n",
    "print(f\"Total unique makes: {df['Make_Cleaned'].nunique()}\")\n",
    "print(f\"Records with 'Other': {(df['Make_Cleaned'] == 'Other').sum()}\")\n",
    "print(f\"Records with 'Unknown': {(df['Make_Cleaned'] == 'Unknown').sum()}\")\n",
    "\n",
    "print(\"\\nFinal distribution of cleaned makes:\")\n",
    "final_counts = df['Make_Cleaned'].value_counts()\n",
    "print(final_counts)\n",
    "\n",
    "print(f\"\\nCleaning complete. Shape: {df.shape}\")\n",
    "print(f\"Make column ready for analysis with {df['Make_Cleaned'].nunique()} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9f3c2",
   "metadata": {},
   "source": [
    "### Inspect Model column\n",
    "- Get rid of any NaNs.\n",
    "- Inspect the column and counts for each model/make. Are model labels unique to each make?\n",
    "- If not, create a derived column that is a unique identifier for a given plane type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "05f20594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11898                  152\n",
      "12384                 LA-4\n",
      "12683                  441\n",
      "13114                  208\n",
      "14259    L-402-2 (LASA-60)\n",
      "Name: Model, dtype: object\n",
      "Missing values in Model column: 18\n",
      "Missing values in Model column after filling: 0\n",
      "Unique models: 3550\n",
      "Top 20 models by count:\n",
      "Model\n",
      "172          772\n",
      "737          403\n",
      "152          317\n",
      "182          304\n",
      "172S         278\n",
      "PA28         273\n",
      "SR22         265\n",
      "172N         250\n",
      "180          213\n",
      "A36          189\n",
      "172M         180\n",
      "PA-18-150    180\n",
      "150          179\n",
      "PA-28-140    168\n",
      "172P         143\n",
      "140          117\n",
      "172R         110\n",
      "170B         107\n",
      "PA-28-161    106\n",
      "PA-28-180    105\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect Model column\n",
    "print(df['Model'].head())\n",
    "# Check for missing values\n",
    "print(f\"Missing values in Model column: {df['Model'].isnull().sum()}\")\n",
    "# Fill missing values with 'Unknown'\n",
    "df['Model'] = df['Model'].fillna('Unknown')\n",
    "print(f\"Missing values in Model column after filling: {df['Model'].isnull().sum()}\")\n",
    "# Check unique values and counts\n",
    "print(f\"Unique models: {df['Model'].nunique()}\")\n",
    "print(\"Top 20 models by count:\")\n",
    "print(df['Model'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f3974da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model/Make combinations:\n",
      "Number of unique models per manufacturer:\n",
      "Make_Cleaned\n",
      "Other                1728\n",
      "Cessna                406\n",
      "Piper                 367\n",
      "Boeing                284\n",
      "Beechcraft            229\n",
      "Airbus                 74\n",
      "Maule                  68\n",
      "Embraer                66\n",
      "Air Tractor            51\n",
      "North American         50\n",
      "McDonnell Douglas      46\n",
      "Grumman                41\n",
      "Aero Commander         37\n",
      "Dehavilland            37\n",
      "Bellanca               36\n",
      "Name: Model, dtype: int64\n",
      "\n",
      "Total unique Make/Model combinations: 3907\n",
      "\n",
      "Top 20 Make/Model combinations by frequency:\n",
      "Make_Cleaned  Model    \n",
      "Cessna        172          769\n",
      "Boeing        737          403\n",
      "Cessna        152          317\n",
      "              182          304\n",
      "              172S         276\n",
      "Piper         PA28         273\n",
      "Cessna        172N         249\n",
      "Cirrus        SR22         240\n",
      "Cessna        180          213\n",
      "              172M         180\n",
      "              150          179\n",
      "Piper         PA-18-150    174\n",
      "              PA-28-140    168\n",
      "Beechcraft    A36          165\n",
      "Cessna        172P         143\n",
      "              140          116\n",
      "              172R         110\n",
      "              170B         107\n",
      "Piper         PA-28-180    105\n",
      "              PA-28-161    102\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#insepect model/make combination\n",
    "print(\"Model/Make combinations:\")\n",
    "models_per_make = df.groupby('Make_Cleaned')['Model'].nunique().sort_values(ascending=False)\n",
    "print(\"Number of unique models per manufacturer:\")\n",
    "print(models_per_make.head(15))\n",
    "\n",
    "# Count records per make/model combination\n",
    "make_model_counts = df.groupby(['Make_Cleaned', 'Model']).size().sort_values(ascending=False)\n",
    "print(f\"\\nTotal unique Make/Model combinations: {len(make_model_counts)}\")\n",
    "print(\"\\nTop 20 Make/Model combinations by frequency:\")\n",
    "print(make_model_counts.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c700b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING UNIQUE PLANE TYPE IDENTIFIER\n",
      "Created unique Plane_Type identifiers: 3904\n",
      "\n",
      "Top 15 most common plane types:\n",
      "Plane_Type\n",
      "Cessna_172         769\n",
      "Boeing_737         403\n",
      "Cessna_152         317\n",
      "Cessna_182         304\n",
      "Cessna_172S        276\n",
      "Piper_PA28         273\n",
      "Cessna_172N        249\n",
      "Cirrus_SR22        240\n",
      "Cessna_180         213\n",
      "Cessna_172M        180\n",
      "Cessna_150         179\n",
      "Piper_PA-18-150    174\n",
      "Piper_PA-28-140    168\n",
      "Beechcraft_A36     165\n",
      "Cessna_172P        143\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#create unique plane type identifier\n",
    "print(\"CREATING UNIQUE PLANE TYPE IDENTIFIER\")\n",
    "# Create unique identifier combining Make and Model\n",
    "df['Plane_Type'] = df['Make_Cleaned'] + '_' + df['Model']\n",
    "\n",
    "# Clean up the identifier (remove special characters, normalize spacing)\n",
    "df['Plane_Type'] = df['Plane_Type'].str.replace(r'[^\\w\\s-]', '', regex=True)  # Remove special chars except hyphens\n",
    "df['Plane_Type'] = df['Plane_Type'].str.replace(r'\\s+', '_', regex=True)       # Replace spaces with underscores\n",
    "df['Plane_Type'] = df['Plane_Type'].str.replace(r'_+', '_', regex=True)        # Remove multiple underscores\n",
    "\n",
    "print(f\"Created unique Plane_Type identifiers: {df['Plane_Type'].nunique()}\")\n",
    "\n",
    "# Verify uniqueness\n",
    "plane_type_counts = df['Plane_Type'].value_counts()\n",
    "print(f\"\\nTop 15 most common plane types:\")\n",
    "print(plane_type_counts.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7b3f80fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION AND SUMMARY\n",
      "Verification of unique identifiers:\n",
      "- Original Models: 3550\n",
      "- Unique Make/Model combinations: 3907\n",
      "- New Plane_Type identifiers: 3904\n",
      "\n",
      "Example transformations:\n",
      "  Cessna + 152 → Cessna_152\n",
      "  Other + LA-4 → Other_LA-4\n",
      "  Cessna + 441 → Cessna_441\n",
      "  Cessna + 208 → Cessna_208\n",
      "  Other + L-402-2 (LASA-60) → Other_L-402-2_LASA-60\n",
      "  Piper + PA-23-250 → Piper_PA-23-250\n",
      "  Grumman + G164A → Grumman_G164A\n",
      "  Cessna + TU206F → Cessna_TU206F\n",
      "  Grumman + F-14A → Grumman_F-14A\n",
      "  Other + DC-9-31 → Other_DC-9-31\n",
      "\n",
      "Final data quality check:\n",
      "- Records with Unknown Make: 0\n",
      "- Records with Unknown Model: 18\n",
      "- Records with Unknown Plane_Type: 18\n",
      "\n",
      "Plane types with 20+ incidents (suitable for analysis): 216\n",
      "Top 10:\n",
      "Plane_Type\n",
      "Cessna_172     769\n",
      "Boeing_737     403\n",
      "Cessna_152     317\n",
      "Cessna_182     304\n",
      "Cessna_172S    276\n",
      "Piper_PA28     273\n",
      "Cessna_172N    249\n",
      "Cirrus_SR22    240\n",
      "Cessna_180     213\n",
      "Cessna_172M    180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Model column inspection complete. Dataset shape: (21428, 36)\n",
      "Ready for analysis with unique Plane_Type identifiers.\n"
     ]
    }
   ],
   "source": [
    "#validation and summary\n",
    "print(\"VALIDATION AND SUMMARY\")\n",
    "\n",
    "# Check if our new identifier resolves the uniqueness issue\n",
    "print(\"Verification of unique identifiers:\")\n",
    "print(f\"- Original Models: {df['Model'].nunique()}\")\n",
    "print(f\"- Unique Make/Model combinations: {len(make_model_counts)}\")\n",
    "print(f\"- New Plane_Type identifiers: {df['Plane_Type'].nunique()}\")\n",
    "\n",
    "# Show some examples of the transformation\n",
    "print(f\"\\nExample transformations:\")\n",
    "sample_data = df[['Make_Cleaned', 'Model', 'Plane_Type']].drop_duplicates().head(10)\n",
    "for _, row in sample_data.iterrows():\n",
    "    print(f\"  {row['Make_Cleaned']} + {row['Model']} → {row['Plane_Type']}\")\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"\\nFinal data quality check:\")\n",
    "print(f\"- Records with Unknown Make: {(df['Make_Cleaned'] == 'Unknown').sum()}\")\n",
    "print(f\"- Records with Unknown Model: {(df['Model'] == 'Unknown').sum()}\")\n",
    "print(f\"- Records with Unknown Plane_Type: {df['Plane_Type'].str.contains('Unknown').sum()}\")\n",
    "\n",
    "# Most frequent plane types for analysis\n",
    "frequent_plane_types = plane_type_counts[plane_type_counts >= 20]  # Threshold for analysis\n",
    "print(f\"\\nPlane types with 20+ incidents (suitable for analysis): {len(frequent_plane_types)}\")\n",
    "print(\"Top 10:\")\n",
    "print(frequent_plane_types.head(10))\n",
    "\n",
    "print(f\"\\nModel column inspection complete. Dataset shape: {df.shape}\")\n",
    "print(f\"Ready for analysis with unique Plane_Type identifiers.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a173ebd",
   "metadata": {},
   "source": [
    "### Cleaning other columns\n",
    "- there are other columns containing data that might be related to the outcome of an accident. We list a few here:\n",
    "- Engine.Type\n",
    "- Weather.Condition\n",
    "- Number.of.Engines\n",
    "- Purpose.of.flight\n",
    "- Broad.phase.of.flight\n",
    "\n",
    "Inspect and identify potential cleaning tasks in each of the above columns. Execute those cleaning tasks. \n",
    "\n",
    "**Note**: You do not necessarily need to impute or drop NaNs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01df492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine.Type column basic info:\n",
      "Missing values: 3956\n",
      "Unique values: 9\n",
      "\n",
      "Value counts:\n",
      "Engine.Type\n",
      "Reciprocating      15005\n",
      "Turbo Prop          1247\n",
      "Turbo Fan            924\n",
      "Unknown              134\n",
      "Turbo Jet            133\n",
      "Geared Turbofan       12\n",
      "Turbo Shaft           11\n",
      "Electric               5\n",
      "UNK                    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample values:\n",
      "['Reciprocating' 'Turbo Prop' 'Turbo Jet' 'Turbo Fan' 'Unknown'\n",
      " 'Turbo Shaft' 'Electric' 'Geared Turbofan' 'UNK']\n",
      "\n",
      "Cleaning tasks identified:\n",
      "- Standardize case and remove extra whitespace\n",
      "- Group rare engine types (< 10 occurrences)\n",
      "\n",
      "After cleaning - Unique values: 8\n",
      "Cleaned value counts:\n",
      "Engine.Type\n",
      "Reciprocating      15005\n",
      "Turbo Prop          1247\n",
      "Turbo Fan            924\n",
      "Unknown              134\n",
      "Turbo Jet            133\n",
      "Geared Turbofan       12\n",
      "Turbo Shaft           11\n",
      "Other                  6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#engine.type column inspection\n",
    "print(\"Engine.Type column basic info:\")\n",
    "print(f\"Missing values: {df['Engine.Type'].isnull().sum()}\")\n",
    "print(f\"Unique values: {df['Engine.Type'].nunique()}\")\n",
    "print(\"\\nValue counts:\")\n",
    "print(df['Engine.Type'].value_counts())\n",
    "\n",
    "print(\"\\nSample values:\")\n",
    "print(df['Engine.Type'].dropna().unique()[:15])\n",
    "\n",
    "# CLEANING TASKS FOR ENGINE.TYPE\n",
    "print(\"\\nCleaning tasks identified:\")\n",
    "print(\"- Standardize case and remove extra whitespace\")\n",
    "print(\"- Group rare engine types (< 10 occurrences)\")\n",
    "\n",
    "# Execute cleaning\n",
    "df['Engine.Type'] = df['Engine.Type'].str.strip().str.title()\n",
    "\n",
    "# Group rare categories\n",
    "engine_counts = df['Engine.Type'].value_counts()\n",
    "rare_engines = engine_counts[engine_counts < 10].index\n",
    "df['Engine.Type'] = df['Engine.Type'].replace(rare_engines, 'Other')\n",
    "\n",
    "print(f\"\\nAfter cleaning - Unique values: {df['Engine.Type'].nunique()}\")\n",
    "print(\"Cleaned value counts:\")\n",
    "print(df['Engine.Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "174a096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weather.Conditions column basic info:\n",
      "Missing values: 2979\n",
      "Unique values: 4\n",
      "\n",
      "Value counts:\n",
      "Weather.Condition\n",
      "VMC    17072\n",
      "IMC     1067\n",
      "Unk      215\n",
      "UNK       95\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample values:\n",
      "['VMC' 'UNK' 'IMC' 'Unk']\n",
      "\n",
      "Cleaning tasks identified:\n",
      "- Standardize case formatting\n",
      "- Check for placeholder values\n",
      "- Group rare weather conditions\n",
      "\n",
      "Checking for potential placeholders:\n",
      "Found potential placeholders with 'Unk': 310\n",
      "Found potential placeholders with '': 18449\n",
      "\n",
      "After cleaning - Unique values: 3\n",
      "Cleaned value counts:\n",
      "Weather.Condition\n",
      "Vmc    17072\n",
      "Imc     1067\n",
      "Unk      310\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#weather.conditions column inspection\n",
    "print(\"\\nWeather.Conditions column basic info:\")\n",
    "\n",
    "print(f\"Missing values: {df['Weather.Condition'].isnull().sum()}\")\n",
    "print(f\"Unique values: {df['Weather.Condition'].nunique()}\")\n",
    "print(\"\\nValue counts:\")\n",
    "print(df['Weather.Condition'].value_counts())\n",
    "\n",
    "print(\"\\nSample values:\")\n",
    "print(df['Weather.Condition'].dropna().unique()[:10])\n",
    "\n",
    "# CLEANING TASKS FOR WEATHER.CONDITION\n",
    "print(\"\\nCleaning tasks identified:\")\n",
    "print(\"- Standardize case formatting\")\n",
    "print(\"- Check for placeholder values\")\n",
    "print(\"- Group rare weather conditions\")\n",
    "\n",
    "# Execute cleaning\n",
    "df['Weather.Condition'] = df['Weather.Condition'].str.strip().str.title()\n",
    "\n",
    "# Check for potential placeholder values\n",
    "print(\"\\nChecking for potential placeholders:\")\n",
    "placeholder_patterns = ['Unk', 'N/A', 'Unknown', 'Not', 'Unavailable', '']\n",
    "for pattern in placeholder_patterns:\n",
    "    mask = df['Weather.Condition'].str.contains(pattern, case=False, na=False)\n",
    "    if mask.any():\n",
    "        print(f\"Found potential placeholders with '{pattern}': {mask.sum()}\")\n",
    "\n",
    "# Group rare categories (< 15 occurrences for weather)\n",
    "weather_counts = df['Weather.Condition'].value_counts()\n",
    "rare_weather = weather_counts[weather_counts < 15].index\n",
    "df['Weather.Condition'] = df['Weather.Condition'].replace(rare_weather, 'Other')\n",
    "\n",
    "print(f\"\\nAfter cleaning - Unique values: {df['Weather.Condition'].nunique()}\")\n",
    "print(\"Cleaned value counts:\")\n",
    "print(df['Weather.Condition'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "981ef13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number.Of.Engines column basic info:\n",
      "Missing values: 2551\n",
      "Data type: float64\n",
      "\n",
      "Value counts:\n",
      "Number.of.Engines\n",
      "0.0        9\n",
      "1.0    15735\n",
      "2.0     3003\n",
      "3.0       36\n",
      "4.0       92\n",
      "6.0        1\n",
      "8.0        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Descriptive statistics:\n",
      "count    18877.000000\n",
      "mean         1.177677\n",
      "std          0.428266\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          8.000000\n",
      "Name: Number.of.Engines, dtype: float64\n",
      "\n",
      "Checking for unrealistic values:\n",
      "Aircraft with >10 engines: 0\n",
      "Aircraft with ≤0 engines: 9\n",
      "\n",
      "Cleaning tasks identified:\n",
      "- Cap unrealistic values (>10 engines)\n",
      "- Handle zero/negative values\n",
      "\n",
      "After cleaning:\n",
      "Value counts:\n",
      "Number.of.Engines\n",
      "1.0    15735\n",
      "2.0     3003\n",
      "3.0       36\n",
      "4.0       92\n",
      "6.0        1\n",
      "8.0        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#number.of.engines column inspection\n",
    "print(\"\\nNumber.Of.Engines column basic info:\")\n",
    "print(f\"Missing values: {df['Number.of.Engines'].isnull().sum()}\")\n",
    "print(f\"Data type: {df['Number.of.Engines'].dtype}\")\n",
    "print(\"\\nValue counts:\")\n",
    "print(df['Number.of.Engines'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDescriptive statistics:\")\n",
    "print(df['Number.of.Engines'].describe())\n",
    "\n",
    "# Check for unrealistic values\n",
    "print(\"\\nChecking for unrealistic values:\")\n",
    "unrealistic_engines = df['Number.of.Engines'] > 10  # Most aircraft have <= 4 engines\n",
    "print(f\"Aircraft with >10 engines: {unrealistic_engines.sum()}\")\n",
    "if unrealistic_engines.any():\n",
    "    print(\"Examples:\")\n",
    "    print(df[unrealistic_engines][['Make_Cleaned', 'Model', 'Number.of.Engines']].head())\n",
    "\n",
    "# Check for zero or negative values\n",
    "zero_negative = df['Number.of.Engines'] <= 0\n",
    "print(f\"Aircraft with ≤0 engines: {zero_negative.sum()}\")\n",
    "\n",
    "# CLEANING TASKS FOR NUMBER.OF.ENGINES\n",
    "print(\"\\nCleaning tasks identified:\")\n",
    "print(\"- Cap unrealistic values (>10 engines)\")\n",
    "print(\"- Handle zero/negative values\")\n",
    "\n",
    "# Execute cleaning\n",
    "# Cap unrealistic values - most commercial aircraft have max 4 engines, military/cargo max ~8\n",
    "df['Number.of.Engines'] = df['Number.of.Engines'].clip(upper=8)\n",
    "\n",
    "# Convert zero/negative to NaN (likely data entry errors)\n",
    "df.loc[df['Number.of.Engines'] <= 0, 'Number.of.Engines'] = np.nan\n",
    "\n",
    "print(f\"\\nAfter cleaning:\")\n",
    "print(\"Value counts:\")\n",
    "print(df['Number.of.Engines'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad63d9",
   "metadata": {},
   "source": [
    "### Column Removal\n",
    "- inspect the dataframe and drop any columns that have too many NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f661bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts per column:\n",
      "Event.Id                      0\n",
      "Investigation.Type            0\n",
      "Accident.Number               0\n",
      "Event.Date                    0\n",
      "Location                      6\n",
      "Country                       1\n",
      "Latitude                   2259\n",
      "Longitude                  2265\n",
      "Airport.Code               7457\n",
      "Airport.Name               7370\n",
      "Injury.Severity             813\n",
      "Aircraft.damage               0\n",
      "Aircraft.Category             0\n",
      "Registration.Number         206\n",
      "Make                          0\n",
      "Model                         0\n",
      "Amateur.Built                 0\n",
      "Number.of.Engines          2560\n",
      "Engine.Type                3956\n",
      "FAR.Description             480\n",
      "Schedule                  18916\n",
      "Purpose.of.flight          3679\n",
      "Air.carrier               11269\n",
      "Total.Fatal.Injuries          0\n",
      "Total.Serious.Injuries        0\n",
      "Total.Minor.Injuries          0\n",
      "Total.Uninjured               0\n",
      "Weather.Condition          2979\n",
      "Broad.phase.of.flight     18619\n",
      "Report.Status              4663\n",
      "Publication.Date            957\n",
      "Total.Passengers              0\n",
      "Serious_Fatal_Rate            0\n",
      "Aircraft_Destroyed            0\n",
      "Make_Cleaned                  0\n",
      "Plane_Type                    0\n",
      "dtype: int64\n",
      "\n",
      "Original shape: (21428, 36)\n",
      "Cleaned shape: (21428, 24)\n",
      "Columns removed: {'Schedule', 'Air.carrier', 'Number.of.Engines', 'Weather.Condition', 'Broad.phase.of.flight', 'Airport.Code', 'Airport.Name', 'Latitude', 'Report.Status', 'Longitude', 'Engine.Type', 'Purpose.of.flight'}\n"
     ]
    }
   ],
   "source": [
    "'''# Inspect the dataframe for columns with NaNs\n",
    "print(\"\\nInspecting columns for NaNs:\")\n",
    "nan_counts = df.isnull().sum()\n",
    "print(nan_counts[nan_counts > 0])\n",
    "\n",
    "# Identify columns with more than 20,000 non-null values\n",
    "non_null_counts = df.notnull().sum()\n",
    "print(\"\\nColumns with more than 20,000 non-null values:\")\n",
    "valid_columns = non_null_counts[non_null_counts > 20000]\n",
    "print(valid_columns)\n",
    "# Drop columns with too many NaNs (less than 20,000 non-nulls)\n",
    "columns_to_drop = nan_counts[nan_counts > (len(df) - 20000)].index.tolist()\n",
    "print(f\"\\nColumns to drop (less than 20,000 non-nulls): {columns_to_drop}\")\n",
    "df.drop(columns=columns_to_drop, inplace=True)'''\n",
    "\n",
    "\n",
    "# First, inspect the dataframe to see null counts\n",
    "print(\"Null counts per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Get columns with more than 20,000 non-null values\n",
    "columns_to_keep = df.columns[df.count() > 20000]\n",
    "\n",
    "# Filter the dataframe\n",
    "df_cleaned = df[columns_to_keep]\n",
    "\n",
    "# Verify the result\n",
    "print(f\"\\nOriginal shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {df_cleaned.shape}\")\n",
    "print(f\"Columns removed: {set(df.columns) - set(df_cleaned.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d48f1",
   "metadata": {},
   "source": [
    "### Save DataFrame to csv\n",
    "- its generally useful to save data to file/server after its in a sufficiently cleaned or intermediate state\n",
    "- the data can then be loaded directly in another notebook for further analysis\n",
    "- this helps keep your notebooks and workflow readable, clean and modularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b425a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv('/Users/karinaburgos/Documents/Flatiron/dsc-course0-m8-lab/data/AviationData_Cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
